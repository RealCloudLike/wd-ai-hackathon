{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module 3: AI Agents with Semantic Kernel\n",
    "## Building Intelligent AI Agents\n",
    "\n",
    "### 1. Introduction to SK Agents\n",
    "Agents in Semantic Kernel are AI-powered entities that can engage in conversations, make decisions, and execute tasks. They can work independently or collaborate in groups to achieve complex goals.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Creating Basic Agents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting chat with Pirate Agent...\n",
      "User: Hello! Can you help me find treasure?\n",
      "Ahoy there, matey! Ye be lookin' fer treasure, eh? Well, we be needin' a map, a hearty crew, and a keen eye fer hidden riches! What kind o' treasure be ye searchin' fer? Gold doubloons, precious gems, or perhaps a stash o' rum? Arrr, let’s set sail on this grand adventure together! *squawk!*\n",
      "\n",
      "User: What's the best way to navigate at sea?\n",
      "Arrr, navigating the vast seas be an art and a science, me hearty! Here be some tips fer ye:\n",
      "\n",
      "1. **Know yer stars**: Learn to read the night sky, fer the North Star be a trusty guide fer findin' true north!\n",
      "\n",
      "2. **Use a compass**: A trusty compass be yer best mate when the stars be hidden by clouds or stormy weather!\n",
      "\n",
      "3. **Chart yer course**: Keep a good nautical chart close at hand. Mark yer waypoints and plot yer journey!\n",
      "\n",
      "4. **Understand the tides**: The ebb and flow o' tides can aid or hinder yer passage; keep an eye on the currents!\n",
      "\n",
      "5. **Watch the weather**: Keep a lookout fer signs of fair weather or stormy seas, fer it can change faster than a brigantine in a gale!\n",
      "\n",
      "6. **Practice dead reckoning**: Calculate yer position based on speed, time, and course—ye can’t always rely on instruments!\n",
      "\n",
      "7. **Stay sharp with sextants**: If ye be fancy, learn to use a sextant to measure angles between the horizon and celestial bodies!\n",
      "\n",
      "With these tools and a bit o' practice, ye'll be navigatin' the seven seas like a true captain! Arrr, happy sailin', matey! *squawk!*\n",
      "\n",
      "User: Tell me about your parrot!\n",
      "Arrr, me parrot be a fine feathered companion, ye see! His name be Polly, and he’s as colorful as a treasure chest full o' jewels! With bright green feathers, a splash o' red on his head, and a beak sharper than a cutlass, he be the pride o' me ship!\n",
      "\n",
      "Polly be not just any parrot, mind ye! He’s a clever bird who can squawk out me favorite pirate phrases and even imitate the sounds o’ the sea. He loves to perch on me shoulder when I’m plotting me next course, and he be known to keep watch fer any scallywags tryin' to sneak up on us!\n",
      "\n",
      "A good parrot can spot fishin' boats or even treasure hunters a mile away, and Polly be no exception! Plus, he knows how to squawk “Walk the plank!” which be always good fer a chuckle among the crew! Arrr, there be nothin' quite like the bond between a pirate and his parrot! *squawk!*\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.agents import ChatCompletionAgent\n",
    "from semantic_kernel.kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "# Create a kernel and add a chat service\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "# Create a simple agent with personality\n",
    "agent = ChatCompletionAgent(\n",
    "    service_id=\"agent\",\n",
    "    kernel=kernel,\n",
    "    name=\"Pirate\",\n",
    "    instructions=\"You are a friendly pirate who always speaks in pirate dialect and ends messages with a parrot sound.\"\n",
    ")\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "\n",
    "# Create chat history and helper function for interaction\n",
    "chat = ChatHistory()\n",
    "\n",
    "async def chat_with_agent(agent: ChatCompletionAgent, message: str):\n",
    "    \"\"\"Function to handle agent interaction\"\"\"\n",
    "    chat.add_user_message(message)\n",
    "    print(f\"User: {message}\")\n",
    "    \n",
    "    # Use streaming for responsive interaction\n",
    "    chunks = []\n",
    "    async for chunk in agent.invoke_stream(chat):\n",
    "        chunks.append(chunk)\n",
    "        print(chunk.content, end=\"\", flush=True)  # Show response as it comes\n",
    "    print(\"\\n\")  # New line after response\n",
    "    \n",
    "    # Add complete response to chat history\n",
    "    complete_response = \"\".join([chunk.content for chunk in chunks])\n",
    "    chat.add_assistant_message(complete_response)\n",
    "\n",
    "print(\"Starting chat with Pirate Agent...\")\n",
    "    \n",
    "    # Test different types of interactions\n",
    "await chat_with_agent(agent, \"Hello! Can you help me find treasure?\")\n",
    "await chat_with_agent(agent, \"What's the best way to navigate at sea?\")\n",
    "await chat_with_agent(agent, \"Tell me about your parrot!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I assist you with your weather-related query today?\n",
      "\n",
      "User: What's the weather like in Seattle?\n",
      "User: Should I pack an umbrella for my trip to London next week?\n",
      "User: Compare the weather in New York and Tokyo.\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "from semantic_kernel.functions.kernel_function_decorator import kernel_function\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "\n",
    "class WeatherPlugin:\n",
    "    \"\"\"Plugin for weather-related functions\"\"\"\n",
    "    \n",
    "    @kernel_function(description=\"Get the current weather for a location.\")\n",
    "    def get_weather(\n",
    "        self,\n",
    "        location: Annotated[str, \"The city name\"]\n",
    "    ) -> str:\n",
    "        # In real implementation, this would call a weather API\n",
    "        return f\"The weather in {location} is sunny and 22°C\"\n",
    "\n",
    "    @kernel_function(description=\"Get the weather forecast for next 3 days.\")\n",
    "    def get_forecast(\n",
    "        self,\n",
    "        location: Annotated[str, \"The city name\"]\n",
    "    ) -> str:\n",
    "        return f\"3-day forecast for {location}: Sunny, Cloudy, Rain\"\n",
    "\n",
    "# Set up kernel with plugins\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"agent\"))\n",
    "\n",
    "# Configure function auto-invocation\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=\"agent\")\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "# Add plugin to kernel\n",
    "kernel.add_plugin(WeatherPlugin(), plugin_name=\"weather\")\n",
    "\n",
    "# Create agent with access to plugins\n",
    "agent = ChatCompletionAgent(\n",
    "    service_id=\"agent\",\n",
    "    kernel=kernel,\n",
    "    name=\"WeatherAssistant\",\n",
    "    instructions=\"\"\"You help users with weather-related queries.\n",
    "    Always aim to provide the most accurate and detailed information possible.\n",
    "    When appropriate, combine current weather with forecast information.\"\"\",\n",
    "    execution_settings=settings\n",
    ")\n",
    "\n",
    "\n",
    "chat = ChatHistory()\n",
    "\n",
    "async def ask_weather(question: str):\n",
    "    chat.add_user_message(question)\n",
    "    print(f\"User: {question}\")\n",
    "\n",
    "async for response in agent.invoke_stream(chat):\n",
    "    print(response.content, end=\"\", flush=True)\n",
    "print(\"\\n\")\n",
    "\n",
    "await ask_weather(\"What's the weather like in Seattle?\")\n",
    "await ask_weather(\"Should I pack an umbrella for my trip to London next week?\")\n",
    "await ask_weather(\"Compare the weather in New York and Tokyo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 96\u001b[0m\n\u001b[1;32m     86\u001b[0m settings\u001b[38;5;241m.\u001b[39mfunction_choice_behavior \u001b[38;5;241m=\u001b[39m FunctionChoiceBehavior\u001b[38;5;241m.\u001b[39mAuto()\n\u001b[1;32m     88\u001b[0m agent_researcher \u001b[38;5;241m=\u001b[39m ChatCompletionAgent(\n\u001b[1;32m     89\u001b[0m     service_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpeerreviewer\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     90\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mkernel,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     93\u001b[0m     execution_settings\u001b[38;5;241m=\u001b[39msettings,\n\u001b[1;32m     94\u001b[0m )\n\u001b[0;32m---> 96\u001b[0m agent_reviewer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m AzureAssistantAgent\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m     97\u001b[0m     service_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresearcher\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     98\u001b[0m     kernel\u001b[38;5;241m=\u001b[39mKernel(),\n\u001b[1;32m     99\u001b[0m     name\u001b[38;5;241m=\u001b[39mREVIEWER_NAME,\n\u001b[1;32m    100\u001b[0m     instructions\u001b[38;5;241m=\u001b[39mREVIEWER_INSTRUCTIONS,\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# Define group chat with termination strategy\u001b[39;00m\n\u001b[1;32m    104\u001b[0m chat \u001b[38;5;241m=\u001b[39m AgentGroupChat(\n\u001b[1;32m    105\u001b[0m     agents\u001b[38;5;241m=\u001b[39m[agent_researcher, agent_reviewer],\n\u001b[1;32m    106\u001b[0m     termination_strategy\u001b[38;5;241m=\u001b[39mApprovalTerminationStrategy(\n\u001b[1;32m    107\u001b[0m         agents\u001b[38;5;241m=\u001b[39m[agent_reviewer], maximum_iterations\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m\n\u001b[1;32m    108\u001b[0m     ),\n\u001b[1;32m    109\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/wd-ai-hackathon/.venv/lib/python3.12/site-packages/semantic_kernel/agents/open_ai/azure_assistant_agent.py:323\u001b[0m, in \u001b[0;36mAzureAssistantAgent.create\u001b[0;34m(cls, kernel, service_id, deployment_name, api_key, endpoint, api_version, ad_token, ad_token_provider, client, default_headers, env_file_path, env_file_encoding, description, id, instructions, name, enable_code_interpreter, code_interpreter_filenames, code_interpreter_file_ids, enable_file_search, vector_store_filenames, vector_store_file_ids, enable_json_response, temperature, top_p, vector_store_id, metadata, max_completion_tokens, max_prompt_tokens, parallel_tool_calls_enabled, truncation_message_count, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m         agent\u001b[38;5;241m.\u001b[39mvector_store_id \u001b[38;5;241m=\u001b[39m vector_store_id\n\u001b[1;32m    321\u001b[0m         assistant_create_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvector_store_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vector_store_id\n\u001b[0;32m--> 323\u001b[0m agent\u001b[38;5;241m.\u001b[39massistant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m agent\u001b[38;5;241m.\u001b[39mcreate_assistant(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39massistant_create_kwargs)\n\u001b[1;32m    324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m agent\n",
      "File \u001b[0;32m/workspaces/wd-ai-hackathon/.venv/lib/python3.12/site-packages/semantic_kernel/agents/open_ai/open_ai_assistant_base.py:298\u001b[0m, in \u001b[0;36mOpenAIAssistantBase.create_assistant\u001b[0;34m(self, ai_model_id, description, instructions, name, enable_code_interpreter, code_interpreter_file_ids, enable_file_search, vector_store_id, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m         create_assistant_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_metadata_key] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    296\u001b[0m     create_assistant_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_options_metadata_key] \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mdumps(execution_settings)\n\u001b[0;32m--> 298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39massistant \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39massistants\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[1;32m    299\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcreate_assistant_kwargs,\n\u001b[1;32m    300\u001b[0m )\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_deleted:\n\u001b[1;32m    303\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_deleted \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m/workspaces/wd-ai-hackathon/.venv/lib/python3.12/site-packages/openai/resources/beta/assistants.py:532\u001b[0m, in \u001b[0;36mAsyncAssistants.create\u001b[0;34m(self, model, description, instructions, metadata, name, response_format, temperature, tool_resources, tools, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;124;03mCreate an assistant with a model and instructions.\u001b[39;00m\n\u001b[1;32m    463\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    529\u001b[0m \u001b[38;5;124;03m  timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    531\u001b[0m extra_headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOpenAI-Beta\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massistants=v2\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(extra_headers \u001b[38;5;129;01mor\u001b[39;00m {})}\n\u001b[0;32m--> 532\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[1;32m    533\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/assistants\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    534\u001b[0m     body\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_maybe_transform(\n\u001b[1;32m    535\u001b[0m         {\n\u001b[1;32m    536\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[1;32m    537\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m\"\u001b[39m: description,\n\u001b[1;32m    538\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: instructions,\n\u001b[1;32m    539\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m: metadata,\n\u001b[1;32m    540\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m: name,\n\u001b[1;32m    541\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[1;32m    542\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtemperature\u001b[39m\u001b[38;5;124m\"\u001b[39m: temperature,\n\u001b[1;32m    543\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtool_resources\u001b[39m\u001b[38;5;124m\"\u001b[39m: tool_resources,\n\u001b[1;32m    544\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtools\u001b[39m\u001b[38;5;124m\"\u001b[39m: tools,\n\u001b[1;32m    545\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_p\u001b[39m\u001b[38;5;124m\"\u001b[39m: top_p,\n\u001b[1;32m    546\u001b[0m         },\n\u001b[1;32m    547\u001b[0m         assistant_create_params\u001b[38;5;241m.\u001b[39mAssistantCreateParams,\n\u001b[1;32m    548\u001b[0m     ),\n\u001b[1;32m    549\u001b[0m     options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[1;32m    550\u001b[0m         extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[1;32m    551\u001b[0m     ),\n\u001b[1;32m    552\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mAssistant,\n\u001b[1;32m    553\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/wd-ai-hackathon/.venv/lib/python3.12/site-packages/openai/_base_client.py:1839\u001b[0m, in \u001b[0;36mAsyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, files, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1825\u001b[0m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1826\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1827\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_AsyncStreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1835\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _AsyncStreamT:\n\u001b[1;32m   1836\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1837\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mawait\u001b[39;00m async_to_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1838\u001b[0m     )\n\u001b[0;32m-> 1839\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls)\n",
      "File \u001b[0;32m/workspaces/wd-ai-hackathon/.venv/lib/python3.12/site-packages/openai/_base_client.py:1533\u001b[0m, in \u001b[0;36mAsyncAPIClient.request\u001b[0;34m(self, cast_to, options, stream, stream_cls, remaining_retries)\u001b[0m\n\u001b[1;32m   1530\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1531\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m-> 1533\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[1;32m   1534\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1535\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   1536\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[1;32m   1537\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1538\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1539\u001b[0m )\n",
      "File \u001b[0;32m/workspaces/wd-ai-hackathon/.venv/lib/python3.12/site-packages/openai/_base_client.py:1634\u001b[0m, in \u001b[0;36mAsyncAPIClient._request\u001b[0;34m(self, cast_to, options, stream, stream_cls, retries_taken)\u001b[0m\n\u001b[1;32m   1631\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39maread()\n\u001b[1;32m   1633\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1634\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1636\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1637\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1638\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1642\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[1;32m   1643\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': '404', 'message': 'Resource not found'}}"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.agents import AgentGroupChat\n",
    "from semantic_kernel.agents.strategies.termination.termination_strategy import TerminationStrategy\n",
    "from semantic_kernel.contents.chat_message_content import ChatMessageContent\n",
    "from semantic_kernel.contents.utils.author_role import AuthorRole\n",
    "from semantic_kernel.agents.open_ai import AzureAssistantAgent, OpenAIAssistantAgent\n",
    "\n",
    "class ApprovalTerminationStrategy(TerminationStrategy):\n",
    "    \"\"\"\n",
    "    Termination Strategy for Peer Review Discussion.\n",
    "\n",
    "    This strategy evaluates the chat history to determine if the discussion\n",
    "    should terminate based on achieving consensus or a clear approval.\n",
    "    \"\"\"\n",
    "\n",
    "    async def should_agent_terminate(self, agent, history):\n",
    "        \"\"\"Evaluate termination condition.\"\"\"\n",
    "        return \"approved\" in history[-1].content.lower()\n",
    "\n",
    "\n",
    "# Configuration for agents' personas and behavior\n",
    "RESEARCHER_NAME = \"AIResearcher\"\n",
    "RESEARCHER_INSTRUCTIONS = \"\"\"\n",
    "Role: AI Researcher\n",
    "Objective: Refine and explain the technical details of a proposed model.\n",
    "Actions:\n",
    "- Answer questions concisely while focusing on scientific rigor.\n",
    "- Propose refinements to improve the clarity and reproducibility of the paper.\n",
    "- Avoid discussing unrelated topics; stay focused on the research at hand.\n",
    "\"\"\"\n",
    "\n",
    "REVIEWER_NAME = \"PeerReviewer\"\n",
    "REVIEWER_INSTRUCTIONS = \"\"\"\n",
    "Role: Peer Reviewer\n",
    "Objective: Evaluate the proposed research paper for clarity, significance, and rigor.\n",
    "Actions:\n",
    "- Identify ambiguities or potential improvements in methodology or claims.\n",
    "- Approve the paper if it meets standards, using the word 'approved'.\n",
    "- Suggest actionable refinements without rephrasing the entire paper.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class ResearchToolsPlugin:\n",
    "    \"\"\"\n",
    "    Plugin for Providing Research-Related Context and Tools.\n",
    "\n",
    "    This plugin supports the agents by offering functionality for citing references,\n",
    "    summarizing research papers, and validating datasets.\n",
    "    \"\"\"\n",
    "\n",
    "    @kernel_function(description=\"Provides a formatted citation for a given paper.\")\n",
    "    def cite_paper(\n",
    "        self, title: Annotated[str, \"The title of the paper.\"],\n",
    "        author: Annotated[str, \"The author of the paper.\"],\n",
    "        year: Annotated[int, \"The year of publication.\"]\n",
    "    ) -> Annotated[str, \"Returns the citation in APA format.\"]:\n",
    "        \"\"\"Generate a citation.\"\"\"\n",
    "        return f\"{author} ({year}). {title}. Journal of AI Research.\"\n",
    "\n",
    "    @kernel_function(description=\"Summarizes the key contributions of a paper.\")\n",
    "    def summarize_paper(\n",
    "        self, abstract: Annotated[str, \"The abstract of the paper.\"]\n",
    "    ) -> Annotated[str, \"Returns a concise summary of the paper's contributions.\"]:\n",
    "        \"\"\"Summarize a research paper's contributions.\"\"\"\n",
    "        return f\"Key Contributions: {abstract[:200]}...\"  # Truncated for brevity.\n",
    "\n",
    "\n",
    "def initialize_kernel_with_research_tools(service_id: str) -> Kernel:\n",
    "    \"\"\"\n",
    "    Initialize a Semantic Kernel instance with Azure Chat Completion and research tools.\n",
    "\n",
    "    Args:\n",
    "        service_id (str): Identifier for the chat service.\n",
    "\n",
    "    Returns:\n",
    "        Kernel: Configured Semantic Kernel instance.\n",
    "    \"\"\"\n",
    "    kernel = Kernel()\n",
    "    kernel.add_service(AzureChatCompletion(service_id=service_id))\n",
    "    kernel.add_plugin(plugin=ResearchToolsPlugin(), plugin_name=\"research_tools\")\n",
    "    return kernel\n",
    "\n",
    "\n",
    "# Initialize the Kernel and agents\n",
    "kernel = initialize_kernel_with_research_tools(\"peerreviewer\")\n",
    "settings = kernel.get_prompt_execution_settings_from_service_id(service_id=\"peerreviewer\")\n",
    "settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "agent_researcher = ChatCompletionAgent(\n",
    "    service_id=\"peerreviewer\",\n",
    "    kernel=kernel,\n",
    "    name=RESEARCHER_NAME,\n",
    "    instructions=RESEARCHER_INSTRUCTIONS,\n",
    "    execution_settings=settings,\n",
    ")\n",
    "\n",
    "agent_reviewer = await AzureAssistantAgent.create(\n",
    "    service_id=\"researcher\",\n",
    "    kernel=Kernel(),\n",
    "    name=REVIEWER_NAME,\n",
    "    instructions=REVIEWER_INSTRUCTIONS,\n",
    ")\n",
    "\n",
    "# Define group chat with termination strategy\n",
    "chat = AgentGroupChat(\n",
    "    agents=[agent_researcher, agent_reviewer],\n",
    "    termination_strategy=ApprovalTerminationStrategy(\n",
    "        agents=[agent_reviewer], maximum_iterations=10\n",
    "    ),\n",
    ")\n",
    "\n",
    "# User initiates the conversation\n",
    "user_input = \"Refine the methodology section of the proposed AI model paper.\"\n",
    "await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "print(f\"# {AuthorRole.USER}: '{user_input}'\")\n",
    "\n",
    "# Process responses from the agents\n",
    "async for response in chat.invoke():\n",
    "    print(f\"# {response.role} - {response.name or '*'}: '{response.content}'\")\n",
    "\n",
    "print(f\"# Chat Complete: {chat.is_complete}\")\n",
    "\n",
    "# Define specialized agents\n",
    "class CodeInspector:\n",
    "    @kernel_function(description=\"Analyze code for bugs\")\n",
    "    def analyze_code(self, code: str) -> str:\n",
    "        # Your implementation\n",
    "        pass\n",
    "\n",
    "class StyleReviewer:\n",
    "    @kernel_function(description=\"Check coding style and conventions\")\n",
    "    def check_style(self, code: str) -> str:\n",
    "        # Your implementation\n",
    "        pass\n",
    "\n",
    "class SecurityAuditor:\n",
    "    @kernel_function(description=\"Identify security vulnerabilities\")\n",
    "    def audit_security(self, code: str) -> str:\n",
    "        # Your implementation\n",
    "        pass\n",
    "\n",
    "class AutoFixer:\n",
    "    @kernel_function(description=\"Suggest code improvements\")\n",
    "    def suggest_fixes(self, code: str) -> str:\n",
    "        # Your implementation\n",
    "        pass\n",
    "\n",
    "# Define the result model\n",
    "class CodeReviewResult(KernelBaseModel):\n",
    "    bugs_found: list[str]\n",
    "    style_issues: list[str]\n",
    "    security_concerns: list[str]\n",
    "    approval_status: str  # \"approved\", \"needs_work\", \"rejected\"\n",
    "    recommended_fixes: list[str]\n",
    "\n",
    "# Initialize the Kernel and agents\n",
    "kernel = Kernel()\n",
    "kernel.add_service(AzureChatCompletion(service_id=\"code_review\"))\n",
    "\n",
    "# Add plugins to kernel\n",
    "kernel.add_plugin(CodeInspector(), plugin_name=\"code_inspector\")\n",
    "kernel.add_plugin(StyleReviewer(), plugin_name=\"style_reviewer\")\n",
    "kernel.add_plugin(SecurityAuditor(), plugin_name=\"security_auditor\")\n",
    "kernel.add_plugin(AutoFixer(), plugin_name=\"auto_fixer\")\n",
    "\n",
    "# Create agents with access to plugins\n",
    "agent_inspector = ChatCompletionAgent(\n",
    "    service_id=\"code_review\",\n",
    "    kernel=kernel,\n",
    "    name=\"CodeInspector\",\n",
    "    instructions=\"Analyze code for bugs and issues.\"\n",
    ")\n",
    "\n",
    "agent_style = ChatCompletionAgent(\n",
    "    service_id=\"code_review\",\n",
    "    kernel=kernel,\n",
    "    name=\"StyleReviewer\",\n",
    "    instructions=\"Check coding style and conventions.\"\n",
    ")\n",
    "\n",
    "agent_security = ChatCompletionAgent(\n",
    "    service_id=\"code_review\",\n",
    "    kernel=kernel,\n",
    "    name=\"SecurityAuditor\",\n",
    "    instructions=\"Identify security vulnerabilities.\"\n",
    ")\n",
    "\n",
    "agent_auto_fixer = ChatCompletionAgent(\n",
    "    service_id=\"code_review\",\n",
    "    kernel=kernel,\n",
    "    name=\"AutoFixer\",\n",
    "    instructions=\"Suggest code improvements.\"\n",
    ")\n",
    "\n",
    "# Define group chat with termination strategy\n",
    "chat = AgentGroupChat(\n",
    "    agents=[agent_inspector, agent_style, agent_security, agent_auto_fixer],\n",
    "    termination_strategy=ApprovalTerminationStrategy(\n",
    "        agents=[agent_inspector, agent_style, agent_security], maximum_iterations=10\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Example code snippets to review\n",
    "code_snippets = [\n",
    "    \"def buggy_function(x): return x / 0\",  # Simple function with bugs\n",
    "    \"def style_issue_function(x):return x*2\",  # Code with style issues\n",
    "    \"def security_vulnerable_function(password): print(password)\"  # Code with security vulnerabilities\n",
    "]\n",
    "\n",
    "# User initiates the conversation\n",
    "for code in code_snippets:\n",
    "    user_input = f\"Review the following code:\\n{code}\"\n",
    "    await chat.add_chat_message(ChatMessageContent(role=AuthorRole.USER, content=user_input))\n",
    "    print(f\"# {AuthorRole.USER}: '{user_input}'\")\n",
    "\n",
    "    # Process responses from the agents\n",
    "    async for response in chat.invoke():\n",
    "        print(f\"# {response.role} - {response.name or '*'}: '{response.content}'\")\n",
    "\n",
    "    print(f\"# Chat Complete: {chat.is_complete}\")\n",
    "\n",
    "# Return structured results\n",
    "review_result = CodeReviewResult(\n",
    "    bugs_found=[\"Division by zero in buggy_function\"],\n",
    "    style_issues=[\"Missing spaces around operator in style_issue_function\"],\n",
    "    security_concerns=[\"Printing password in security_vulnerable_function\"],\n",
    "    approval_status=\"needs_work\",\n",
    "    recommended_fixes=[\"Fix division by zero\", \"Add spaces around operators\", \"Avoid printing sensitive information\"]\n",
    ")\n",
    "print(review_result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
    "gender:\n",
    "age:\n",
    "alignment:\n",
    "bio:\n",
    "email:\n",
    "interests (real life):\n",
    "interests (virtual, online):\n",
    "political_views:\n",
    "social_views:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "from datetime import date\n",
    "\n",
    "from faker import Faker\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.console import Console\n",
    "from schwarm.core.schwarm import Schwarm\n",
    "from schwarm.models.types import Agent, ContextVariables, Result\n",
    "from schwarm.utils.settings import APP_SETTINGS\n",
    "from tinydb import TinyDB\n",
    "\n",
    "fake = Faker()\n",
    "console = Console()\n",
    "console.clear()\n",
    "APP_SETTINGS.DATA_FOLDER = \"\"\n",
    "\n",
    "db = TinyDB(f\"{APP_SETTINGS.DATA_FOLDER}/db.json\")\n",
    "\n",
    "\n",
    "class User(BaseModel):\n",
    "    \"\"\"User model.\"\"\"\n",
    "\n",
    "    real_name: str = Field(..., title=\"Real Name\")\n",
    "    user_name: str = Field(..., title=\"User Name\")\n",
    "    gender: str = Field(..., title=\"gender\")\n",
    "    birthday: str = Field(..., title=\"Birthday\")\n",
    "    age: int = Field(..., title=\"Age\")\n",
    "    alignment: str = Field(..., title=\"Alignment\")\n",
    "    bio: str = Field(..., title=\"Bio\")\n",
    "    job: str = Field(..., title=\"Job\")\n",
    "    email: str = Field(..., title=\"Email\")\n",
    "    interests_real: str = Field(..., title=\"Interests (real life)\")\n",
    "    interests_virtual: str = Field(..., title=\"Interests (virtual, online)\")\n",
    "    political_views: str = Field(..., title=\"Political Views\")\n",
    "    social_views: str = Field(..., title=\"Social Views\")\n",
    "\n",
    "\n",
    "# Agents\n",
    "\n",
    "user_generator = Agent(name=\"User Generator\")\n",
    "bio_generator = Agent(name=\"Biography Generator\")\n",
    "\n",
    "# Instructions\n",
    "\n",
    "\n",
    "def instruction_user_generator(context_variables: ContextVariables) -> str:\n",
    "    instruction = \"\"\"\n",
    "    You are a helpful agent specialized in choosing the right tool for the task at hand.\n",
    "    Task: Generating fake users for a virtual forum.\n",
    "    \"\"\"\n",
    "    return instruction\n",
    "\n",
    "\n",
    "def instruction_bio_generator(context_variables: ContextVariables) -> str:\n",
    "    instruction = \"\"\"\n",
    "    You are a helpful agent specialized in choosing the right tool for the task at hand.\n",
    "    Task: Generate a bio for a fake user.\n",
    "    \"\"\"\n",
    "    return instruction\n",
    "\n",
    "\n",
    "user_generator.instructions = instruction_user_generator\n",
    "bio_generator.instructions = instruction_bio_generator\n",
    "\n",
    "\n",
    "# Functions\n",
    "\n",
    "\n",
    "def get_random_alignment() -> str:\n",
    "    \"\"\"Get a random alignment.\"\"\"\n",
    "    algnmt = random.randint(1, 9)\n",
    "    alignment = \"True Neutral\"\n",
    "    if algnmt == 1:\n",
    "        alignment = \"Lawful Good\"\n",
    "    elif algnmt == 2:\n",
    "        alignment = \"Neutral Good\"\n",
    "    elif algnmt == 3:\n",
    "        alignment = \"Chaotic Good\"\n",
    "    elif algnmt == 4:\n",
    "        alignment = \"Lawful Neutral\"\n",
    "    elif algnmt == 5:\n",
    "        alignment = \"True Neutral\"\n",
    "    elif algnmt == 6:\n",
    "        alignment = \"Chaotic Neutral\"\n",
    "    elif algnmt == 7:\n",
    "        alignment = \"Lawful Evil\"\n",
    "    elif algnmt == 8:\n",
    "        alignment = \"Neutral Evil\"\n",
    "    elif algnmt == 9:\n",
    "        alignment = \"Chaotic Evil\"\n",
    "    return alignment\n",
    "\n",
    "\n",
    "def get_gender() -> str:\n",
    "    r = random.randint(0, 100)\n",
    "    gender = \"M\"\n",
    "    if r > 80:\n",
    "        gender = \"F\"\n",
    "    return gender\n",
    "\n",
    "\n",
    "def get_birthdate() -> date:\n",
    "    \"\"\"Get a random birthdate.\"\"\"\n",
    "    return fake.date_of_birth(minimum_age=18, maximum_age=80)\n",
    "\n",
    "\n",
    "def transfer_user_data_to_biography_generator(context_variables: ContextVariables) -> Result:\n",
    "    \"\"\"Generate a bio for a user.\"\"\"\n",
    "    # Generate some fields with faker\n",
    "\n",
    "    # Gender with a 80% chance of being male and 20% of being female\n",
    "\n",
    "    profile = fake.profile(sex=get_gender())  # type: ignore\n",
    "    birthdate = get_birthdate()\n",
    "\n",
    "    user = User(\n",
    "        real_name=str(profile[\"name\"]),\n",
    "        user_name=\"\",\n",
    "        gender=str(profile[\"sex\"]),\n",
    "        birthday=str(birthdate),\n",
    "        age=2024 - birthdate.year,  # type: ignore\n",
    "        alignment=get_random_alignment(),  # type: ignore\n",
    "        bio=\"\",\n",
    "        job=str(profile[\"job\"]),\n",
    "        email=str(profile[\"mail\"]),\n",
    "        interests_real=\"\",\n",
    "        interests_virtual=\"\",\n",
    "        political_views=\"\",\n",
    "        social_views=\"\",\n",
    "    )\n",
    "    context_variables[\"user\"] = user\n",
    "    return Result(value=f\"{user}\", context_variables=context_variables, agent=bio_generator)\n",
    "\n",
    "\n",
    "def transer_user_bio_to_user_generator(\n",
    "    context_variables: ContextVariables,\n",
    "    user_name: str,\n",
    "    biography: str,\n",
    "    interests_real: str,\n",
    "    interests_virtual: str,\n",
    "    political_views: str,\n",
    "    social_views: str,\n",
    ") -> Result:\n",
    "    \"\"\"Save user bio to database.\n",
    "\n",
    "    The bio should be a short, but informative text that gives a clear picture of the user.\n",
    "    It should fit the alignment of the user, and the rest of the profile, like age and job\n",
    "\n",
    "    Arguments:\n",
    "        user_name: The user name of the user. The more creative the better.\n",
    "        biography: The biography of the user. Short, but informative. Should give a clear picture of the user.\n",
    "        interests_real: The real life interests of the user. comma seperated tags.\n",
    "        interests_virtual: The virtual interests of the user. comma seperated tags.\n",
    "        political_views: The political views of the user. comma seperated tags.\n",
    "        social_views: The social views of the user. comma seperated tags.\n",
    "    \"\"\"\n",
    "    user = context_variables[\"user\"]\n",
    "    if \"count\" in context_variables:\n",
    "        context_variables[\"count\"] += 1\n",
    "    else:\n",
    "        context_variables[\"count\"] = 1\n",
    "    count = context_variables[\"count\"]\n",
    "    if isinstance(user, User):\n",
    "        user.bio = biography\n",
    "        user.user_name = user_name\n",
    "        user.interests_real = interests_real\n",
    "        user.interests_virtual = interests_virtual\n",
    "        user.political_views = political_views\n",
    "        user.social_views = social_views\n",
    "    context_variables[\"user\"] = user\n",
    "    db.insert(user.dict())  # type: ignore\n",
    "    console.print(f\"User {context_variables['count']}:\\n{biography}\")\n",
    "    return Result(value=f\"User #{count}: {user}\", context_variables=context_variables, agent=user_generator)\n",
    "\n",
    "\n",
    "user_generator.functions = [transfer_user_data_to_biography_generator]\n",
    "bio_generator.functions = [transer_user_bio_to_user_generator]\n",
    "\n",
    "response = Schwarm().quickstart(user_generator, \"Start generating!\", mode=\"auto\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
